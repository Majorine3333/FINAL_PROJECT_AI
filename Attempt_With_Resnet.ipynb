{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oED9WjB_sRfu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os as os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTcCEUg5wvKK",
        "outputId": "e5ef4cb5-f10c-481d-9d5a-8c8fe4dd83eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w1XqSrVJ2SRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/DATASET_AI_PROJECT/Brain_Tumor_Dataset/archive (2)/Training'\n",
        "print(os.path.exists(dataset_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO-2_uP915tx",
        "outputId": "5de5d3b5-bec4-4a7e-8d4f-23b6a5b637ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the dataset folder\n",
        "dataset_path = '/content/drive/MyDrive/DATASET_AI_PROJECT/Brain_Tumor_Dataset/archive (2)/Training'\n",
        "\n",
        "# Initialize a dictionary to hold image filenames for specified labels\n",
        "data = {\n",
        "    'glioma_tumor': [],\n",
        "    'meningioma_tumor': [],\n",
        "    'notumor': [],\n",
        "    'pituitary_tumor': []\n",
        "}\n",
        "\n",
        "# Iterate through each folder in the dataset\n",
        "for folder in data.keys():\n",
        "    label_folder = os.path.join(dataset_path, folder.replace('_tumor', '') if 'tumor' in folder else 'notumour')\n",
        "    if os.path.isdir(label_folder):  # Ensure it's a directory\n",
        "        for image_filename in os.listdir(label_folder):\n",
        "            if image_filename.endswith(('.jpg', '.png', '.jpeg')):  # Check for image files\n",
        "                data[folder].append(image_filename)\n",
        "\n",
        "# Create a DataFrame with specified labels as column headings\n",
        "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
        "\n",
        "#df.to_csv('/content/drive/MyDrive/Processed_Medical_Data/Data.csv', index=False)\n",
        "\n",
        "#print(\"CSV file created successfully!\")"
      ],
      "metadata": {
        "id": "P8rm0bRCws_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2  # library for reading images files\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "# Example directory structure\n",
        "dataset_dir = '/content/drive/MyDrive/DATASET_AI_PROJECT/Brain_Tumor_Dataset/archive (2)/Training'\n",
        "\n",
        "#When using a pretrained model for MRI brain tumor detection, you typically do not need to manually preprocess each image as extensively\n",
        "\n",
        "#To have equal and compatible size as input into the model, the images were resized to 256x256 pixels\n",
        "# Load pretrained ResNet50 model without top layers\n",
        "input_shape = (224, 224,3)\n",
        "\n",
        "\n",
        "img_path = '/content/drive/MyDrive/DATASET_AI_PROJECT/Brain_Tumor_Dataset/archive (2)/Training'\n",
        "\n",
        "def normalize_intensity(img):\n",
        "    \"\"\"\n",
        "    Normalize the intensity values of the input image to [0, 1].\n",
        "\n",
        "    Parameters:\n",
        "    - img: Input image as a numpy array.\n",
        "\n",
        "    Returns:\n",
        "    - Normalized image as a numpy array.\n",
        "    \"\"\"\n",
        "    # Ensure the image is converted to float32 for safe division\n",
        "    img = img.astype(np.float32)\n",
        "\n",
        "    # Normalize the image to the range [0, 1]\n",
        "    img_min = np.min(img)\n",
        "    img_max = np.max(img)\n",
        "\n",
        "    if img_max != img_min:\n",
        "        normalized_img = (img - img_min) / (img_max - img_min)\n",
        "    else:\n",
        "        normalized_img = img / 255.0  # Handle the case when img_min == img_max (all pixels are the same)\n",
        "\n",
        "    return normalized_img\n",
        "\n",
        "def apply_histogram_equalization(img):\n",
        "    \"\"\"\n",
        "    Apply histogram equalization to the input image.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Input image as a numpy array (assuming grayscale).\n",
        "\n",
        "    Returns:\n",
        "    - Image with histogram equalization applied.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure image is in 8-bit unsigned integer format (CV_8UC1)\n",
        "    if img.dtype != np.uint8:\n",
        "        img = img.astype(np.uint8)\n",
        "\n",
        "     # Ensure image is grayscale\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:  # RGB image\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply histogram equalization using OpenCV\n",
        "    equalized_img = cv2.equalizeHist(img)\n",
        "\n",
        "    # Expand dimensions if the image was originally grayscale\n",
        "    if len(img.shape) > 2 and img.shape[2] == 3:\n",
        "        equalized_img = np.expand_dims(equalized_img, axis=2)\n",
        "    # # Convert grayscale to RGB again\n",
        "    # if len(img.shape) == 2 or img.shape[2] == 1:\n",
        "    #     img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    return equalized_img\n",
        "\n",
        "\n",
        "def custom_preprocessing(img):\n",
        "    # Apply intensity normalization\n",
        "    normalized_img = normalize_intensity(img)\n",
        "\n",
        "    # Apply histogram equalization (assuming grayscale images)\n",
        "    #equalized_img = apply_histogram_equalization(normalized_img)\n",
        "\n",
        "    #convert to rbg\n",
        "    return normalized_img\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Flow from directory with classes automatically inferred from subfolders\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # Adjust class_mode based on your dataset (binary/multi-class)\n",
        "    shuffle=True\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "images, labels = next(train_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGN117rx3t5I",
        "outputId": "50482026-8ced-4a4f-99e2-c14e2a49de1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4850 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BYWpklYXwiil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = train_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_indices.items()}\n",
        "print(\"Class Labels Mapping:\", class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRzpmNEu43YL",
        "outputId": "0ec65fb8-8df6-4b50-a407-356045b52cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Labels Mapping: {0: 'glioma', 1: 'meningioma', 2: 'notumor', 3: 'pituitary'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessed_dir='/content/drive/MyDrive/DATASET_AI_PROJECT/Brain_Tumor_Dataset/Processed_Medical_Data/Training'"
      ],
      "metadata": {
        "id": "gsHkNLKIwTEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACTING FEATURES\n"
      ],
      "metadata": {
        "id": "2Tz6QhozYeqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load ResNet50 model without top layer (classifier)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Create a model that outputs features\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "# Extract features for training data\n",
        "def extract_features(generator):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = model.predict(inputs_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(labels_batch)\n",
        "    return np.vstack(features), np.vstack(labels)\n",
        "\n",
        "train_features, train_labels = extract_features(train_generator)\n",
        "validation_features, validation_labels = extract_features(validation_generator)"
      ],
      "metadata": {
        "id": "db2jopy-iA4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7793114-934d-42b1-ebf2-63b672602ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING MODEL WITH CLASSIFICATION ANN MODEL\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvFygDnCPucB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Define a new model for classification\n",
        "classification_model = Sequential([\n",
        "    Flatten(input_shape=train_features.shape[1:]),  # Flatten the features\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(train_labels.shape[1], activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "classification_model.compile(optimizer='adam',\n",
        "                              loss='categorical_crossentropy',\n",
        "                              metrics=['accuracy'])\n",
        "\n",
        "# Train the classification model\n",
        "classification_model.fit(train_features, train_labels,\n",
        "                         epochs=10,\n",
        "                         batch_size=32,\n",
        "                         validation_data=(validation_features, validation_labels))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HOCTq0GkuyXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATE AND USE YOUR MODEL\n"
      ],
      "metadata": {
        "id": "9OGxcnFGgMkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = classification_model.evaluate(validation_features, validation_labels)\n",
        "print(f'Validation loss: {loss}')\n",
        "print(f'Validation accuracy: {accuracy}')\n",
        "\n",
        "# Use the model for predictions\n",
        "predictions = classification_model.predict(validation_features)"
      ],
      "metadata": {
        "id": "DUxZcKUGgQUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}